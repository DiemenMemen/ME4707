{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tarea_03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFgfJYMMg53o"
      },
      "source": [
        "# Tarea 3: Redes Neuronales\n",
        "\n",
        "ME4707 - Robótica - Semestre 2020-2\n",
        "\n",
        "Profesor: Juan C. Zagal - Ayudante Laboratorio: Gaspar Fábrega"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Erx-dZsh-Gb"
      },
      "source": [
        "# 1. Introducción\n",
        "\n",
        "Entre los algoritmos más comunes dentro del Machine Learning (ML) se encuentran las Redes Neuronales o Neural Networks (NN) que son algoritmos bioinspirados en la forma en que nuestro cerebros procesan información mediante transmisión de señales eléctricas entre las neuronas. Al igual que la mente de un bebé va aprendiendo al ir experimentando y creciendo, las redes neuronales aprenden del error. En el caso del Aprendizaje Supervisado es posible utilizar conjuntos de entrenamiento donde existen pares de datos de entrada y salida `(X, Y)`, ya conocidos, para que la red aprenda de estos a extraer las características y patrones necesarios para llevar a cabo la tarea deseada, ya sea de clasificación o regresión. \n",
        "\n",
        "De este modo, inicialmente las redes comienzan por predecir resultados totalmente erróneos a partir de los datos entregados. No obstante, a medida que esta va siendo entrenada, va ajustando sus parámetros internos para corregir sus respuestas y acercarse los más posible a los resultados esperados.\n",
        "\n",
        "Las Neural Networks se estructuran en una red de nodos generalmente ordenados por capas, que mediante una serie de ponderaciones y conexiones convierten una serie de inputs X en outputs Y. Dependiendo de como se estructuren las redes neuronales, estas pueden cumplir diferentes funciones, permitiéndoles ser aplicadas en una gran variedad de problemas, desde prevensión de fraudes bancarios hasta detección de tumores mediante radiografías.\n",
        "\n",
        "En esta tarea los problemas se abordarán desde un punto de vista más analítico, acercando a las y los estudiantes al funcionamiento y programación de redes neuronales al observar el desempeño de estas en problemas de distinta índole."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSSicothhB2F"
      },
      "source": [
        "# 2. Formato de entrega\n",
        "La tarea se desarrollará en [Google Colab](https://colab.research.google.com/) en un entorno de Python 3. Debe trabajar sobre este mismo archivo .ipynb completando lo que se requiere en cada problema. Se debe entregar:\n",
        "- Reporte de resultados (en un archivo .pdf) y análisis de estos de acuerdo con las distintas partes de la tarea.\n",
        "- En el archivo .ipynb deben dejar la mejor red que hayan logrado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka_Y-k5pmXFu"
      },
      "source": [
        "# 3. Problema Clasificación ANN\n",
        "\n",
        "Se comenzará por analizar un problema de clasificación bastante simple inspirado en el Neural Network Playground de TensorFlow (https://playground.tensorflow.org). En este caso, los puntos son segmentados o bien, etiquetados, en dos regiones dentro de los cuadrantes que se muestran en el diagrama a continuación. Así, el objetivo de nuestro modelo será clasificar la etiqueta de los puntos dentro de este espacio apartir del par de puntos $(x1, x2)$ como valores de entrada.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/cherrerab/roboticafcfm/master/tarea_03/bin/problema_01_ref.png\" height=\"280\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uBnDJKcJZ_w"
      },
      "source": [
        "## 3.1 Dataset\n",
        "En este problema se dispone de una serie de puntos (dataset) en el espacio cartesiano $(x_1, x_2)$, los cuales son clasificados en base a su posición en el espacio. Lea con atención el código a continuación que permite la generación de este dataset `(X, Y)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTKbZ-EQotNa"
      },
      "source": [
        "# generación dataset------\n",
        "\n",
        "# importar librerías\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import cos, sin, pi\n",
        "\n",
        "# cantidad de datos en el dataset\n",
        "data_size = 5000\n",
        "\n",
        "# proporción de ruido en el dataset\n",
        "data_noise = 0.25\n",
        "\n",
        "# inicializar sets de datos\n",
        "# X contiene los puntos cartesianos (x, y)\n",
        "# Y contiene las etiquetas de clasificación de cada punto\n",
        "# donde 1 significa que se encuentra dentro del radio y 0 que no.\n",
        "X = np.zeros( (data_size, 2) )\n",
        "Y = np.zeros( (data_size, 2) )\n",
        "\n",
        "# generar datos al azar\n",
        "for i in np.arange(data_size):\n",
        "  x1 = 2*random.random() - 1\n",
        "  x2 = 2*random.random() - 1\n",
        "\n",
        "  # agregar al set X de puntos\n",
        "  X[i, 0] = x1\n",
        "  X[i, 1] = x2\n",
        "\n",
        "  # agregar etiqueta al set Y\n",
        "  if cos(x1*3*pi)*cos(x2*3*pi) > 0.0:\n",
        "    Y[i, 0] = 0\n",
        "    Y[i, 1] = 1\n",
        "  else:\n",
        "    Y[i, 0] = 1\n",
        "    Y[i, 1] = 0\n",
        "\n",
        "  # agregar ruido al dato (utilizado más adelante)\n",
        "  if random.random() < data_noise:\n",
        "    Y[i, :] = 1 - Y[i, :]\n",
        "\n",
        "# plotear distribución en el dataset\n",
        "plt.figure( figsize=(7,7) )\n",
        "plt.scatter(X[:,0], X[:,1], c=Y[:,0], cmap='plasma', alpha=0.5, s=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jI1-3xiwCxK"
      },
      "source": [
        "## 3.2 Data Splitting\n",
        "\n",
        "Teniendo ya el dataset para el entrenamiento de la NN, se debe dividir este en dos sets: uno de entrenamiento (`training set`) y otro de testing (`testing set`). El primero es utilizado, como su nombre lo indica, en el entrenamiento de la red neuronal; mientras que el segundo es utilizado para evaluar el _accuracy_ de la red ya entrenada.\n",
        "\n",
        "Como la red es evaluada con datos que \"nunca ha visto\" durante el entrenamiento, este resultado permite observar si la red ha logrado generalizar el problema o si se ha _overfitteado_ (aprenderse los datos de entrenamiento de \"memoria\").\n",
        "\n",
        "El _data splitting_ se puede lograr con el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avkm6Zb-xTLA"
      },
      "source": [
        "# importar librerías\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# generar sets de datos de training y testing\n",
        "# la varibale test_size permite controlar la proporción entre los datos de testing y training.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moJfwvqayZZ3"
      },
      "source": [
        "## 3.3 Model Setup\n",
        "\n",
        "Con los sets de entrenamiento y testing listos se puede dar paso a la configuración y entrenamiento de la red neuronal. Para esto se utilizará la librería `keras` o `tf.keras` de `TensorFlow`. Keras es una API de alto nivel para la creación y el entrenamiento de modelos de deep learning. Está orientada y diseñada para la construcción de modelos de forma modular o en bloques. De este modo, ofrece un framework mucho más amigable e intuitivo para principiantes, a la vez que mantiene un estructura personalizable y versátil que permite a usuarios más avanzados incorporar nuevas ideas.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/cherrerab/deeplearningfallas/master/workshop_02/bin/keras_logo.png\" width=\"400\">\n",
        "\n",
        "Los elemenos básicos para la construcción de un modelo o `keras.Model` consisten en las capas o `layers` del modelo. En este sentido, configurar un modelo en Keras resulta en ir uniendo o conectando capas `keras.layers` de manera secuencial.\n",
        "\n",
        "Para comenzar e introducir el framework de esta librería, construiremos un modelo o red neuronal `Sequential` a partir de únicamente capas `keras.layers.Dense` y otras capas elementales.\n",
        "- https://keras.io/api/layers/\n",
        "- https://keras.io/api/layers/activations/\n",
        "\n",
        "En términos generales, compondremos nuestro modelo de una serie de capas `Dense`, que se encargarán de procesar la información y los patrones de los datos de entrada hasta una última capa `Dense` con únicamente dos nodos que determinarán las etiquetas de los puntos $(x_1, x_2)$ que se ingresen al modelo.\n",
        "A continuación se presenta el código necesario para configurar una red de este tipo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3d8gHTl3HRZ"
      },
      "source": [
        "# importar librerías\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import plot_model\n",
        "\n",
        "# inicializar modelo keras.Sequential\n",
        "model = Sequential()\n",
        "\n",
        "# ---\n",
        "# primero debemos agregar nuestra capa Input donde debemos especificar\n",
        "# las dimensiones de los datos que se ingresarán al modelo\n",
        "input_dim = ( 2, )\n",
        "model.add( Input( shape=input_dim ) )\n",
        "\n",
        "# ---\n",
        "# ahora debemos ir agregando nuestras capas Dense.\n",
        "# https://keras.io/api/layers/core_layers/dense/\n",
        "\n",
        "# las keras.layers.Dense reciben la cantidad de nodos o units dentro\n",
        "# de la capa y la función de activación que operarán.\n",
        "# https://keras.io/api/layers/activations/\n",
        "\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 256, activation = 'tanh'))\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "\n",
        "# ---\n",
        "# por último debemos configurar nuestra capa de salida\n",
        "# dado que el modelo consiste en uno de clasificación emplearemos\n",
        "# la función softmax, donde cada nodo indicará la probabilidad de que\n",
        "# los datos correspondan a una de las etiquetas o estados de salud.\n",
        "labels_num = 2\n",
        "model.add(Dense(units = labels_num, activation = 'softmax'))\n",
        "\n",
        "# imprimir resumen del modelo\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_68VoSFy3nDn"
      },
      "source": [
        "Parte de este analisis consiste en experimentar con distintas cantidades de capas, nodos e incluso funciones de activación (https://keras.io/activations/). Sientase en libertad de modificar la arquitectura de esta red según le parezca.\n",
        "\n",
        "Para entrenar esta red o bien llamado, modelo, basta compilarlo y entrenarlo con los sets de datos generados anteriormente. En este caso utilizaremos los datos de `testing` como datos de validación para monitorear directamente el desempeño del modelo sobre el conjunto de evaluación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7qcROlC4jJf"
      },
      "source": [
        "# ---\n",
        "# compilar modelo siguiendo como función de pérdida\n",
        "# la categorical crossentropy, 'categorical_crossentropy'\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# ---\n",
        "# realizar rutina de entrenamiento\n",
        "train_history = model.fit(X_train, Y_train,\n",
        "                          batch_size=128, epochs=200,\n",
        "                          validation_data=(X_test, Y_test) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjQOjt5Q6xW8"
      },
      "source": [
        "## 3.3 Model Evaluation\n",
        "\n",
        "Para evaluar el desempeño de este modelo de clasificación existen múltiples herramientas:\n",
        "-  Gráfico de función de pérdida: La función de pérdida o _loss function_ es el paramétro que se va optimizando a medida que la red se entrena. La red neuronal va ajustando los pesos de ponderación entre los nodos tal de minimizar este paramétro. En el gráfico de función de perdida se puede visualizar el desempeño del entrenamiento del modelo y además la convergencia entre la curva de `training` y `validation`. Si la curva de `validation` se escapa considerablemente de la curva de `training` esto es un indicador de que el modelo ha sufrido _overfitting_ y por tanto ha perdido generalidad (se aprende los datos de `training` de memoria).\n",
        "\n",
        "- Matriz de confusión: Esta tabla permite comparar las predicciones del modelo versus las etiquetas reales de los datos.\n",
        "\n",
        "- Heat Map o Mapa de Clasificación: En el caso de modelos que operan sobre datos 2D, o en el espacio cartesiano, es posible visualizar el resultado de la red neuronal dentro de todo el dominio de los datos (espacio cartesiano). Así es posible visualizar de forma más directa el criterio de clasificación del modelo.\n",
        "\n",
        "Dentro del github del curso `roboticafcfm` se encuentran implementadas las funciones `plot_loss_function`, `plot_confusion_matrix` y `plot_classification_map` para facilitar el uso de estas herramientas. Para cargarlas dentro del entorno de Colab debe ejecutar el siguiente bloque de código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-KOch-unAqr"
      },
      "source": [
        "!git clone https://github.com/cherrerab/roboticafcfm.git\r\n",
        "%cd /content/roboticafcfm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIi1m3g4HlOE"
      },
      "source": [
        "Una vez importado el github del curso, ejecute el siguiente bloque de código y observe los resultados del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDQW43jr6jtl"
      },
      "source": [
        "from utils import plot_loss_function\n",
        "from utils import plot_confusion_matrix\n",
        "from utils import plot_classification_map\n",
        "\n",
        "# obtener predicciones de X_test con model.predict\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# para que el resultado nos sea más intuitivo transformaremos\n",
        "# las etiquetas nuevamente a non one-hot-encoding\n",
        "# utilizando np.argmax\n",
        "Y_pred = np.argmax(Y_pred, axis = 1)\n",
        "Y_true = np.argmax(Y_test, axis = 1)\n",
        "\n",
        "# plot gráfico de función de pérdida\n",
        "plot_loss_function(train_history)\n",
        "\n",
        "# matriz de confusión\n",
        "plot_confusion_matrix(Y_true, Y_pred,\n",
        "                      target_names=['Azul', 'Amarillo'], figsize=(6, 6))\n",
        "\n",
        "# classification map\n",
        "plot_classification_map(model, (0,1), (0,1), 256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gL7fiL_I5dC"
      },
      "source": [
        "## 3.4 Preguntas\n",
        "\n",
        "- Registre los resultados de esta primera red neuronal \"simple\" en su reporte. Luego, agregue más capas a la red y aumente la cantidad de nodos de estas. También pruebe utilizando distintas funciones de activación. Mejore la red lo más posible procurando maximizar el parámetro _val_acc_ mostrado durante el entrenamiento (mientras más cercano a 1.0 mejor). Registre los resultados de esta red mejorada y comente sobre la razón de este mejor desempeño.\n",
        "- En la sección en que se genera el dataset existe el parámetro _data_noise_, este define el porcentaje de ruido a agregar al dataset. Elija tres valores entre [0.05, 0.5] y entrene su red mejorada con estos tres nuevos sets con ruido. Registre los resultados y comente sobre los cambios en el desempeño (utilice los gráficos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TsASAJAaWsq"
      },
      "source": [
        "# 4. Problema Clasificación CNN\n",
        " \n",
        "A partir del problema anterior, es claro que las redes neuronales son capaces de resolver problemas de clasificación simples, incluso ante la presencia de algo de ruido. La pregunta entonces radica si son capaces de resolver problemas de clasificación más complejos, como por ejemplo, clasificación de imágenes digitales.\n",
        "\n",
        "En este problema se trabajará con un dataset que contiene cerca de 60.000 imágenes de `32x32px` correspondientes a 10 clases distintas (perros, ranas, barcos, camiones, etc.) llamado CIFAR-10. El objetivo de este problema es desarrollar una Red Neuronal Convolucional o Convolutional Neural Network (CNN) capaz de discernir entre las distintas clases y lograr clasificar correctamente cada imagen de acuerdo a su clase correspondiente.\n",
        "\n",
        "Mas información sobre el dataset: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/944/1*6XQqOifwnmplS22zCRRVaw.png\" height=\"250\"> <img src=\"https://raw.githubusercontent.com/cherrerab/roboticafcfm/master/tarea_03/bin/problema_02_ref.png\" height=\"250\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vrPid3sfUXu"
      },
      "source": [
        "## 4.1 Dataset\n",
        "\n",
        "El dataset CIFAR-10 puede ser obtenido corriendo el código a continuación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLn-dQ1D0eRo"
      },
      "source": [
        "# importar librerías\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# importar sets de training y testing\n",
        "(X_train, Y_train_non_one_hot), (X_test, Y_test_non_one_hot) = cifar10.load_data()\n",
        "\n",
        "# ---\n",
        "# visualizar algunas imágenes dentro del dataset\n",
        "imgs = np.hstack( [X_train[0,:,:], X_train[100,:,:],\n",
        "                   X_train[217,:,:], X_train[500,:,:]] )\n",
        "\n",
        "plt.figure( figsize=(10,10) )\n",
        "plt.imshow(imgs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OavprQGiiEXJ"
      },
      "source": [
        "Como se puede observar, el dataset ya se encuentra separado en sets de training y testing. No obstante, es necesario algo de procesamiento previo al entrenamiento. Corra el bloque de código a continuación para preparar los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_cmSDIKiEGJ"
      },
      "source": [
        "# importar librerías\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# ---\n",
        "# dado que las etiquetas no vienen con one-hot encoding las transformamos a estas.\n",
        "# one-hot-encoding consiste en codificar las etiquetas de la forma [0, 0, 1]\n",
        "# cuando, por ejemplo, se tienen tres clases. Así, esta estructura es compatible\n",
        "# con la salida de una capa softmax.\n",
        "\n",
        "# para esto se puede utilizar la función to_categorical de keras.utils\n",
        "Y_train = to_categorical(Y_train_non_one_hot, 10)\n",
        "Y_test = to_categorical(Y_test_non_one_hot, 10)\n",
        "\n",
        "# ---\n",
        "# para un experimento posterior aislaremos las clases correspondientes\n",
        "# a las clases de perros y gatos, donde la etiqueta 5 corresponde a perros\n",
        "# y la etiqueta 3 a gatos.\n",
        "X_dc_train = np.zeros( (10000, 32, 32, 3) )\n",
        "Y_dc_train = np.zeros( (10000, 1) )\n",
        "\n",
        "X_dc_test = np.zeros( (2000, 32, 32, 3) )\n",
        "Y_dc_test = np.zeros( (2000, 1) )\n",
        "\n",
        "\n",
        "n = 0\n",
        "# recorreremos todas la imágenes en cifar-10\n",
        "for i in range(X_train.shape[0]):\n",
        "  # si tiene la etiqueta correspondiente a perro\n",
        "  if (Y_train_non_one_hot[i][0] == 5):\n",
        "    # agregamos la imágen al dataset\n",
        "    X_dc_train[n,:,:,:] = X_train[i,:,:,:]\n",
        "    Y_dc_train[n] = 0\n",
        "    n = n+1\n",
        "\n",
        "  # si tiene la etiqueta correspondiente a gato\n",
        "  elif (Y_train_non_one_hot[i][0] == 3):\n",
        "    X_dc_train[n,:,:,:] = X_train[i,:,:,:]\n",
        "    Y_dc_train[n] = 1\n",
        "    n = n+1\n",
        "\n",
        "# datos testing\n",
        "n = 0\n",
        "for i in range(X_test.shape[0]):\n",
        "  # si tiene la etiqueta correspondiente a perro\n",
        "  if (Y_test_non_one_hot[i][0] == 5):\n",
        "    X_dc_test[n,:,:,:] = X_test[i,:,:,:]\n",
        "    Y_dc_test[n] = 0\n",
        "    n = n+1\n",
        "  # si tiene la etiqueta correspondiente a gato\n",
        "  elif (Y_test_non_one_hot[i][0] == 3):\n",
        "    X_dc_test[n,:,:,:] = X_test[i,:,:,:]\n",
        "    Y_dc_test[n] = 1\n",
        "    n = n+1\n",
        "\n",
        "# pasamos a one hot encoding\n",
        "Y_dc_train = to_categorical(Y_dc_train, 2)\n",
        "Y_dc_test = to_categorical(Y_dc_test, 2)\n",
        "\n",
        "# ---\n",
        "# mostrar ejemplos\n",
        "imgs = np.hstack( [X_dc_train[0,:,:], X_dc_train[100,:,:],\n",
        "                   X_dc_train[200,:,:], X_dc_train[300,:,:]] )\n",
        "\n",
        "plt.figure( figsize=(10,10) )\n",
        "plt.imshow(np.uint8(imgs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG321nYIkngF"
      },
      "source": [
        "## 4.2 Model Setup\n",
        "En el desarrollo de una red CNN hay tres nuevos tipos de capas a tomar en consideración.\n",
        "- Conv2D (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D): Esta capa en vez de componerse de nodos se compone de filtros (como los vistos en el capítulo de visión computacional), cada uno de estos filtros es convolucionado con la imagen de entrada produciendo una nueva imagen _filtrada_ que pasa a la siguiente capa.\n",
        "- MaxPooling2D (https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D): A medida que avanza la información a través de la red, conviene ir reduciendo el tamaño de las imágenes tal de ir aislando únicamente la información relevante (_features_). Además, así se reduce significativamente el costo computacional durante el entrenamiento. Este tipo de capas reduce las dimensiones de las imágenes que entran a estas.\n",
        "\n",
        "- Flatten (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten): Dado que después de todo este es un problema de clasificación, la última capa debe consistir en un par de nodos softmax que entreguen las etiquetas. Para conectar las imágenes de las capas anteriores a esta capa (o a capas Dense) es necesario agregar una capa Flatten que transforme la información de las imágenes en vectores de 1D.\n",
        "\n",
        "A continuación, se presenta una arquitectura bastante simple de una CNN que cumpla el propósito de este problema. La idea es que, al igual que en el problema anterior, vaya modificando la arquitectura tal de mejorarla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbWw3_o95HP"
      },
      "source": [
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.utils import plot_model\n",
        "\n",
        "# inicializar modelo keras.Sequential\n",
        "model = Sequential()\n",
        "\n",
        "# ---\n",
        "# primero debemos agregar nuestra capa Input donde debemos especificar\n",
        "# las dimensiones de los datos que se ingresarán al modelo\n",
        "# las capas Conv2D reciben tensores de la forma (height, width, channels)\n",
        "input_dim = ( 32, 32, 3)\n",
        "model.add( Input( shape=input_dim ) )\n",
        "\n",
        "# ---\n",
        "# ahora debemos ir agregando nuestras capas Conv2D y Pooling.\n",
        "\n",
        "# las keras.layers.Conv2D reciben la cantidad de filtros dentro de la capa,\n",
        "# el tamaño de estos filtros y la función de activación con que operarán.\n",
        "# https://keras.io/api/layers/convolution_layers/convolution2d/\n",
        "\n",
        "# las keras.layers.MaxPooling2D reciben el tamaño de la ventana sobre\n",
        "# la cual llevarán a cabo el down-sampling\n",
        "# https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(Dropout(rate = 0.2))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters = 48, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(Conv2D(filters = 48, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(Dropout(rate = 0.3))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
        "\n",
        "# ---\n",
        "# ahora debemos ir agregando nuestras capas Dense para procesar la\n",
        "# información hasta la capa de salida.\n",
        "# https://keras.io/api/layers/core_layers/dense/\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(rate = 0.4))\n",
        "\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 64, activation = 'relu'))\n",
        "model.add(Dense(units = 32, activation = 'relu'))\n",
        "\n",
        "\n",
        "# ---\n",
        "# por último debemos configurar nuestra capa de salida\n",
        "# dado que el modelo consiste en uno de clasificación emplearemos\n",
        "# la función softmax, donde cada nodo indicará la probabilidad de que\n",
        "# los datos correspondan a una de las etiquetas (10 clases).\n",
        "model.add(Dense(units = 10, activation = 'softmax'))\n",
        "\n",
        "# imprimir resumen del modelo\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rQiJLbNpo23"
      },
      "source": [
        "Luego, al igual que en el caso anterior, para entrenar esta red o bien llamado, modelo, basta compilarlo y entreneralo con los sets de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqxF0TS7pzsW"
      },
      "source": [
        "# ---\n",
        "# compilar modelo siguiendo como función de pérdida\n",
        "# la categorical crossentropy, 'categorical_crossentropy'\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# ---\n",
        "# realizar rutina de entrenamiento\n",
        "train_history = model.fit(X_train, Y_train,\n",
        "                          batch_size=128, epochs=200,\n",
        "                          validation_data=(X_test, Y_test) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_73_8jCqlBn"
      },
      "source": [
        "## 4.3 Model Evaluation\n",
        "\n",
        "Para evaluar el desempeño de este modelo de clasificación corra el código a continuación.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqcXm0uGq1JV"
      },
      "source": [
        "from utils import plot_loss_function\n",
        "from utils import plot_confusion_matrix\n",
        "from utils import plot_classification_map\n",
        "\n",
        "# ---\n",
        "# obtener etiquetas predichas a partir del modelo, mediante model.predict\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# para que el resultado nos sea más intuitivo transformaremos\n",
        "# las etiquetas nuevamente a non one-hot-encoding\n",
        "# utilizando np.argmax\n",
        "Y_pred = np.argmax(Y_pred, axis = 1)\n",
        "Y_true = np.argmax(Y_test, axis = 1)\n",
        "\n",
        "# plot gráfico de función de pérdida\n",
        "plot_loss_function(train_history)\n",
        "\n",
        "# matriz de confusión\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "plot_confusion_matrix(Y_true, Y_pred,\n",
        "                      target_names=class_names, figsize=(6, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8-HsAtsrLoV"
      },
      "source": [
        "## 4.4 Preguntas\n",
        "- Modifique la arquitectura de la red hasta mejorarla lo más posible (un _val_acc_ sobre 0.6 o 0.7 es suficiente). Agregue a su reporte un esquema de la arquitectura de su red e incluya los gráficos resultantes. Comente sobre el desempeño en la clasificación. ¿Entre que clases suele confundirse más? ¿Tienen sentido estas confusiones?\n",
        "- Ahora, cree otra red que trabaje con los sets (X_dc_train, X_dc_test, Y_dc_train y Y_dc_test) para desarrollar una red que clasifique entre perros y gatos. Trate de mejorarla lo más posible y comente sobre los resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P62HjwE9QS-Q"
      },
      "source": [
        "# para trabajar con los sets X_dc_train, X_dc_test, Y_dc_train y Y_dc_test se\r\n",
        "# va a usar una red prácticamente similar, solamente cambiando el número de \r\n",
        "# outputs a 2, pues en este caso se trabaja con dos clases\r\n",
        "\r\n",
        "import keras \r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Input\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import MaxPooling2D\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.utils import plot_model\r\n",
        "\r\n",
        "# inicializar modelo keras.Sequential\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# ---\r\n",
        "# primero debemos agregar nuestra capa Input donde debemos especificar\r\n",
        "# las dimensiones de los datos que se ingresarán al modelo\r\n",
        "# las capas Conv2D reciben tensores de la forma (height, width, channels)\r\n",
        "input_dim = ( 32, 32, 3)\r\n",
        "model.add( Input( shape=input_dim ) )\r\n",
        "\r\n",
        "# ---\r\n",
        "# ahora debemos ir agregando nuestras capas Conv2D y Pooling.\r\n",
        "\r\n",
        "# las keras.layers.Conv2D reciben la cantidad de filtros dentro de la capa,\r\n",
        "# el tamaño de estos filtros y la función de activación con que operarán.\r\n",
        "# https://keras.io/api/layers/convolution_layers/convolution2d/\r\n",
        "\r\n",
        "# las keras.layers.MaxPooling2D reciben el tamaño de la ventana sobre\r\n",
        "# la cual llevarán a cabo el down-sampling\r\n",
        "# https://keras.io/api/layers/pooling_layers/max_pooling2d/\r\n",
        "\r\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\r\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\r\n",
        "model.add(Dropout(rate = 0.2))\r\n",
        "\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "model.add(Conv2D(filters = 48, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\r\n",
        "model.add(Conv2D(filters = 48, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\r\n",
        "model.add(Dropout(rate = 0.3))\r\n",
        "\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\r\n",
        "\r\n",
        "# ---\r\n",
        "# ahora debemos ir agregando nuestras capas Dense para procesar la\r\n",
        "# información hasta la capa de salida.\r\n",
        "# https://keras.io/api/layers/core_layers/dense/\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dropout(rate = 0.4))\r\n",
        "\r\n",
        "model.add(Dense(units = 128, activation = 'relu'))\r\n",
        "model.add(Dense(units = 64, activation = 'relu'))\r\n",
        "model.add(Dense(units = 32, activation = 'relu'))\r\n",
        "\r\n",
        "# ---\r\n",
        "# por último debemos configurar nuestra capa de salida\r\n",
        "# dado que el modelo consiste en uno de clasificación emplearemos\r\n",
        "# la función softmax, donde cada nodo indicará la probabilidad de que\r\n",
        "# los datos correspondan a una de las etiquetas (2 clases).\r\n",
        "model.add(Dense(units = 2, activation = 'softmax'))\r\n",
        "\r\n",
        "# ---\r\n",
        "# compilar modelo siguiendo como función de pérdida\r\n",
        "# la categorical crossentropy, 'categorical_crossentropy'\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "# ---\r\n",
        "# realizar rutina de entrenamiento\r\n",
        "train_history = model.fit(X_dc_train, Y_dc_train,\r\n",
        "                          batch_size=128, epochs=200,\r\n",
        "                          validation_data=(X_dc_test, Y_dc_test) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ziZB7KnRSW8"
      },
      "source": [
        "from utils import plot_loss_function\r\n",
        "from utils import plot_confusion_matrix\r\n",
        "from utils import plot_classification_map\r\n",
        "\r\n",
        "# ---\r\n",
        "# obtener etiquetas predichas a partir del modelo, mediante model.predict\r\n",
        "Y_pred = model.predict(X_dc_test)\r\n",
        "\r\n",
        "# para que el resultado nos sea más intuitivo transformaremos\r\n",
        "# las etiquetas nuevamente a non one-hot-encoding\r\n",
        "# utilizando np.argmax\r\n",
        "Y_pred = np.argmax(Y_pred, axis = 1)\r\n",
        "Y_true = np.argmax(Y_dc_test, axis = 1)\r\n",
        "\r\n",
        "# plot gráfico de función de pérdida\r\n",
        "plot_loss_function(train_history)\r\n",
        "\r\n",
        "# matriz de confusión\r\n",
        "class_names = ['cat', 'dog']\r\n",
        "plot_confusion_matrix(Y_true, Y_pred,\r\n",
        "                      target_names=class_names, figsize=(6, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv2erQ-dEeHT"
      },
      "source": [
        "# 5. Problema Regresión ANN\n",
        "\n",
        "Un problema común en procesamiento de imágenes digitales es el método de interpolación utilizado al aumentar la resolución de una imagen (por ejemplo al aumentar el tamaño de una de 256x256 a 1080x1080).\n",
        "En esta sección se desarrollará una red neuronal de regresión que sea capaz de \"aprender\" una imagen y permita aumentar su resolución de forma más sofisticada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF6EQ_NfFb_a"
      },
      "source": [
        "## 5.1 Dataset\n",
        "En este caso el dataset consiste en una única imagen en escala de grises a partir del cual se construyen los sets de datos de entrenamiento.\n",
        "El problema se reduce a predecir la intensidad de un pixel a partir de su posición normalizada $(x, y)$ dentro de la imagen. Corra el código a continuación para generar los sets de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_DMfGDGHbAb"
      },
      "source": [
        "# importar librerías\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# leer imagen\n",
        "img = cv2.imread('/content/roboticafcfm/tarea_03/cat_700.jpg')\n",
        "\n",
        "# transformar a escala de grises\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img = cv2.resize(img, (256, 256))\n",
        "img = np.float32( img/255.0 )\n",
        "\n",
        "# mostrar imagen\n",
        "fig = plt.figure()\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geC7KAZiIhNc"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ---\n",
        "# obtener dimensiones originales de la imagen\n",
        "w, h = img.shape\n",
        "\n",
        "# inicializar sets de datos\n",
        "X = np.zeros( (w*h, 2) )\n",
        "Y = np.zeros( (w*h, 1) )\n",
        "\n",
        "# por cada pixel en la imagen\n",
        "n = 0\n",
        "for  i in range(w):\n",
        "  for j in range(h):\n",
        "    # registrar posiciones (x, y) normalizadas entre [0.0, 1.0]\n",
        "    X[n, 0] = i/(w-1)\n",
        "    X[n, 1] = j/(h-1)\n",
        "\n",
        "    # registrar intensidad del pixel\n",
        "    Y[n] = img[j, i]\n",
        "\n",
        "    n = n + 1\n",
        "\n",
        "# ---\n",
        "# generar sets de datos de training y testing\n",
        "# la varibale test_size permite controlar la proporción entre los datos de testing y training.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.5, random_state = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0f0vle8KR-c"
      },
      "source": [
        "## 5.2 Model Setup\n",
        "La arquitectura de la NN de este problema es en escencia igual a la del primer problema. La red debe recibir (input) la posición normalizada $(x, y)$ del pixel a predecir y retornar (output) la intensidad del pixel. Así, un input de dos nodos y un output de un solo nodo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMAFvYFHLInX"
      },
      "source": [
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import plot_model\n",
        "\n",
        "# inicializar modelo keras.Sequential\n",
        "model = Sequential()\n",
        "\n",
        "# ---\n",
        "# primero debemos agregar nuestra capa Input donde debemos especificar\n",
        "# las dimensiones de los datos que se ingresarán al modelo\n",
        "input_dim = ( 2, )\n",
        "model.add( Input( shape=input_dim ) )\n",
        "\n",
        "# ---\n",
        "# ahora debemos ir agregando nuestras capas Dense.\n",
        "# https://keras.io/api/layers/core_layers/dense/\n",
        "\n",
        "model.add(Dense(units = 512, activation = \"relu\"))\n",
        "model.add(Dense(units = 256, activation = \"relu\"))\n",
        "model.add(Dense(units = 128, activation = \"relu\"))\n",
        "model.add(Dense(units = 256, activation = \"relu\"))\n",
        "model.add(Dense(units = 128, activation = \"relu\"))\n",
        "model.add(Dense(units = 64, activation = \"relu\"))\n",
        "model.add(Dense(units = 32, activation = \"relu\"))\n",
        "model.add(Dense(units = 16, activation = \"relu\"))\n",
        "model.add(Dense(units = 8, activation = \"relu\"))\n",
        "model.add(Dense(units = 4, activation = \"relu\"))\n",
        "model.add(Dense(units = 2, activation = \"relu\"))\n",
        "\n",
        "# ---\n",
        "# por último debemos configurar nuestra capa de salida\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "\n",
        "# imprimir resumen del modelo\n",
        "model.summary()\n",
        "\n",
        "# ---\n",
        "# compilar modelo siguiendo como función de pérdida\n",
        "# el error cuadrado medio, 'mse'.\n",
        "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "# ---\n",
        "# realizar rutina de entrenamiento\n",
        "train_history = model.fit(X_train, Y_train,\n",
        "                          batch_size=128, epochs=200,\n",
        "                          validation_data=(X_test, Y_test) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-aZqfmLM5rN"
      },
      "source": [
        "## 5.3 Model Evaluation\n",
        "Ahora se debe comprobar si el modelo es capaz de mejorar la resolución de la imagen de forma inteligente.\n",
        "Corra el siguiente bloque de código para evaluar el desempeño del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKJCKL8LNdjq"
      },
      "source": [
        "# plotear gráfico de función de pérdida\n",
        "plot_loss_function(train_history)\n",
        "\n",
        "# aumentar dimensión de la imagen\n",
        "width, height = ( 1000, 1000)\n",
        "\n",
        "# generar posiciones normalizadas de la nueva imagen\n",
        "X_res = np.zeros( ((width*height), 2) )\n",
        "n = 0\n",
        "for i in range(width):\n",
        "  for j in range(height):\n",
        "    X_res[n, 0] = i/(width-1) # pos x\n",
        "    X_res[n, 1] = j/(height-1) # pos y\n",
        "    n = n+1\n",
        "\n",
        "# predecir intensidades de cada uno de los pixeles en X_pred\n",
        "Y_orig = model.predict(X)\n",
        "Y_orig = np.reshape(Y_orig, (h, w))\n",
        "Y_orig = Y_orig.transpose()\n",
        "\n",
        "# predecir intensidades de cada uno de los pixeles en X_pred\n",
        "Y_res = model.predict(X_res)\n",
        "Y_res = np.reshape(Y_res, (height, width))\n",
        "Y_res = Y_res.transpose()\n",
        "\n",
        "# mostrar imagen original\n",
        "print('Imagen original')\n",
        "fig = plt.figure()\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# mostrar output en dimensiones originales\n",
        "print('Imagen resultante del modelo en dimensiones originales')\n",
        "fig = plt.figure()\n",
        "plt.imshow(Y_orig, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# mostrar output en nuevas dimensiones\n",
        "print('Imagen resultante del modelo en las nuevas dimensiones')\n",
        "fig = plt.figure(figsize=(18,18))\n",
        "plt.imshow(Y_res, cmap='gray')\n",
        "plt.axis('off')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fwN2O3T3DkM"
      },
      "source": [
        "## 5.4 Preguntas\n",
        "\n",
        "- Modifique la arquitectura de la red hasta mejorarla lo más posible. Utilizando la función __model.summary()__ obtenga la cantidad de pesos que contiene su red en total. Considerando que cada peso de la red corresponde a un float de 32 bits y que en una imagen en escala de grises cada pixel corresponde a un entero de 8 bits, comente hasta que punto vale la pena entrenar una red de este tipo para \"comprimir\" una imagen."
      ]
    }
  ]
}
