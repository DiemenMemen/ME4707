{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tarea_01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZlMp79fYtoB"
      },
      "source": [
        "# Tarea 1: Visión Computacional\n",
        "# Diemen Delgado C.\n",
        "ME4707 - Robótica - Semestre 2020-2\n",
        "\n",
        "Profesor: Juan C. Zagal - Auxiliar: Cristián Herrera - Laboratorios: Gaspar Fábrega"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rHieWNXYtoG"
      },
      "source": [
        "# Instalación\n",
        "## 1. Google Colab\n",
        "En esta tarea, que se trabajará durante los laboratorios computacionales 1, 2, 3 y 4, se utilizará Python 3 y la librería de visión computacional OpenCV. La forma más fácil de tener un ambiente de desarrollo de Python con todas las bibliotecas más comunes es utilizar **Google Colaboratory**. Colaboratory es un entorno Jupyter notebook gratuito que se ejecuta completamente en la nube. Puede escribir y ejecutar código, solo requiere de una cuenta google.\n",
        "\n",
        "https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "\n",
        "Debe trabajar sobre este mismo archivo .ipynb completando lo que se solicita en cada problema.\n",
        "\n",
        "## 2. OpenCV\n",
        "En esta tarea se utilizará principalmente **OpenCV**. La Open Surce Computer Vision es una librería especializada en herramientas de visión computacional y en todo lo que respecta a visión artificial en general. De este modo provee de funcionalidades de todo tipo de complejidad, desde operaciones básicas de procesamiento de imágenes, hasta algoritmos de reconocimiento de objetos.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/cherrerab/roboticafcfm/master/auxiliar_01/bin/opencv_logo.png\" height=\"200\">\n",
        "\n",
        "Por supuesto, esta librería cuenta con su documentación correspondiente. En esta puede encontrar descripciones más detalladas de sus funcionalidades, así como también ejemplos, tutoriales y otros.\n",
        "\n",
        "https://docs.opencv.org/master/\n",
        "\n",
        "Si bien OpenCV se encuentra instalada por defecto en Colab bajo el nombre de `cv2`, en esta tarea requerirá herramientas que por temas de patente no se encuentran disponibles directamente en esta librería. Por esto, instalaremos una librería complementaria `opencv_contrib` en su version `3.3.0.10`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BJCovyDtgs7",
        "outputId": "4380f1de-6273-4a38-a061-6b074f3c1101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "# instalar version 3.3\n",
        "!pip install opencv-python==3.3.0.10 \n",
        "!pip install opencv-contrib-python==3.3.0.10\n",
        "\n",
        "# importar opencv\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-LXxRoQlzcJ"
      },
      "source": [
        "##3. Imágenes\n",
        "\n",
        "Para facilitar la carga de los archivos necesarios para completar la tarea, se ha habilitado un directorio en el github del curso `roboticafcfm`. Para clonar el repositorio en el entorno de Colab solo debe ejecutar el siguiente bloque de código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zirn0JPfhgAO",
        "outputId": "4ba42d08-db1f-4813-a109-e890137c2d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!git clone https://github.com/cherrerab/roboticafcfm.git\n",
        "%cd /content/roboticafcfm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjHQkzp_m2RG"
      },
      "source": [
        "# Problema 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3d6KazRJe-t"
      },
      "source": [
        "## Parte 1\n",
        "Como se ha visto en las clases del curso, las imágenes digitales consisten en arreglos discretos de valores numéricos, donde cada valor define la intensidad de iluminación que posee un punto `pixel` específico en la imagen.\n",
        "\n",
        "Por ejemplo, cargue la imagen `balls.jpg` e imprima las dimensiones de esta. Esto lo puede hacer mediante el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V09stGwGqbky",
        "outputId": "b492818f-4959-4e6b-8684-67c0e3ab1bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# el módulo matplotlib.plt nos permite visualizar las imágenes\n",
        "# el módulo numpy contiene herramientas para arreglos numéricos\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# para leer una imagen, hay que ingresar su ubicación en la función cv2.imread\n",
        "img = cv2.imread('tarea_01//images//balls.jpg')\n",
        "\n",
        "# las dimensiones de la imagen pueden ser obtenidas utilizando el atributo .shape\n",
        "print('la imagen balls.jpg tiene dimensiones: ', img.shape )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIQhH81stGXQ"
      },
      "source": [
        "Se puede notar que la imagen es un arreglo/matriz de 3 dimensiones `640x640x3`. En este caso, el primer valor corresponde a la altura `height` de la imagen, el segundo al ancho `width` de esta, y el último a la cantidad de canales que posee. Así, se trata de una imagen de 640x640 de 3 canales RGB.\n",
        "\n",
        "Ahora, al cargar imágenes utilizando cv2.imread estas son cargadas como BGR y no RGB, por lo que los canales están mal asignados. Para corregir esto existe la función `cv2.cvtColor` con la cual es posible cambiar el colorspace de la imagen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5TXwwnpuVms",
        "outputId": "0f274655-80f3-408e-b660-0cb91a277d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# leer imagen\n",
        "img = cv2.imread('tarea_01//images//balls.jpg')\n",
        "\n",
        "# mostrar imagen en BGR\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "\n",
        "# corregir a RGB\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# mostrar imagen en RGB (correcta)\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis('off')\n",
        "\n",
        "# también se puede convertir a escala de grises\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_gray, cmap='gray')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ijPIyLjqci2"
      },
      "source": [
        "Como se puede ver, la imagen consiste principalmente en 3 bolas de luz (dos rojas y una de color verde). No obstante, existe bastante contenido adicional que no parece muy relevante y que podría ser removido. Así, se podría procesar la imagen de tal manera de aislar las bolas tal como se muestra en la imagen `balls_masked.png`.\n",
        "\n",
        "Para lograr lo anterior se puede generar una máscara `mask` a partir de una imagen binarizada y multiplicar esta con la imagen original. Una forma de binarizar una imagen es utilizando la función `cv2.inRange(img, umbral, 255)`. También se puede utilizar la función `cv2.threshold`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V86LOwtF2lWB",
        "outputId": "c0863552-eeeb-4bb2-e902-e60c4381d791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# leer imagen\n",
        "img = cv2.imread('tarea_01//images//balls.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# convertir a escala de grises\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_gray, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# binarizar con cv2.inRange (los valores de la máscara deben estar entre 0 y 1)\n",
        "mask = cv2.inRange(img_gray, 50, 255)\n",
        "mask = mask/255\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(mask, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# multiplicar máscara con imagen original\n",
        "img_mask = np.zeros_like(img)\n",
        "\n",
        "for c in range(img_mask.shape[2]):\n",
        "  img_mask[:,:,c] = np.multiply(img[:,:,c], mask)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_mask)\n",
        "plt.axis('off')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DORDNTdz2p8P"
      },
      "source": [
        "En el ejemplo anterior no se lograron aislar por completo las bolas de luz debido a que el umbral seleccionado en la binarización no es el adecuado. Un método para determinar este umbral es analizando el histograma de la imagen.\n",
        "\n",
        "Los histogramas de una imagen, corresponden a la representación gráfica de la distribución de las intensidades al interior de la imagen. Estos pueden ser generados utilizando la función `plt.hist(array, bins)`, donde el parámetro `array` consiste en el `np.array` a procesar, mientras que `bins` determina la discretización del histograma.\n",
        "\n",
        "(a) Convierta la imagen a escala de grises y visualice su histograma (cree una nueva figura para esto y utilice la función `plt.hist` sobre `img.flatten()`). A partir del histograma, determine el umbral adecuado para la máscara y genere la imagen con las esféras aisladas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWSAoZ6QFijh",
        "outputId": "21bb345d-337a-40d8-a97c-f989c4de5d2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# RESPUESTA PREGUNTA 1 PARTE 1.a\n",
        "\n",
        "# 1. leer la imagen (RGB)\n",
        "img = cv2.imread('tarea_01//images//balls.jpg')\n",
        "rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 2. convertir a escala de grises\n",
        "gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# 3. plotear histograma de la imagen en escala de grises\n",
        "gray_flat = gray.flatten()\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.hist(gray_flat)\n",
        "plt.title(\"Histograma de la escala de grises\")\n",
        "\n",
        "# 4. crear máscara binaria a partir del umbral del histograma\n",
        "\n",
        "# A partir del histograma se decide que el umbral es 150\n",
        "pre_mask  =cv2.inRange(gray, 150, 255)\n",
        "mask = pre_mask/255\n",
        "\n",
        "# 5. multiplicar imagen original con máscara y visualizar\n",
        "img_mask = np.zeros_like(rgb)\n",
        "\n",
        "for i in range(img_mask.shape[2]):\n",
        "  img_mask[:,:,i] = np.multiply(rgb[:,:,i], mask)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_mask)\n",
        "plt.title(\"Máscara 1 aplicada a balls.jpg\")\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YY8KYX2GW-m"
      },
      "source": [
        "\n",
        "b) Suponga que ahora solo desea segmentar la esfera de color verde. Sobre la imagen RGB elija el canal correspondiente y obtenga una nueva máscara correspondiente al requisito anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxM3O0bbI6H-",
        "outputId": "3c6a9b36-97f5-4ce7-d707-4853cdc11613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# RESPUESTA PREGUNTA 1 PARTE 1.b\n",
        "\n",
        "# 1. leer la imagen (RGB)\n",
        "img = cv2.imread('tarea_01//images//balls.jpg')\n",
        "rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 2. seleccionar canal de la imagen\n",
        "green = rgb[:, :, 1]\n",
        "\n",
        "# 3. plotear histograma del canal\n",
        "green_flat = green.flatten()\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.hist(green_flat,15)\n",
        "plt.title(\"Histograma del canal g\")\n",
        "\n",
        "# 4. crear máscara binaria a partir del umbral del histograma\n",
        "\n",
        "# En el histograma se ven tres zonas: oscuridad, bolas rojas y bola verde\n",
        "# se decide un umbral de 230\n",
        "pre_mask = cv2.inRange(green, 235, 255)\n",
        "mask = pre_mask/255\n",
        "\n",
        "# 5. multiplicar imagen original con máscara y visualizar\n",
        "img_mask = np.zeros_like(rgb)\n",
        "\n",
        "for i in range(img_mask.shape[2]):\n",
        "  img_mask[:,:,i] = np.multiply(rgb[:,:,i], mask)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_mask)\n",
        "plt.title(\"Máscara 2 aplicada a balls.jpg\")\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trckpJIfJiTk"
      },
      "source": [
        "## Parte 2\n",
        "\n",
        "Parte importante en el procesamiento de imágenes digitales es la aplicación de transformaciones (lineales y no-lineales) sobre los valores numéricos de estas. Para introducir esta idea, considere el siguiente problema sobre la imagen en escala de grises `old.jpg`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXdOnatkJXlh",
        "outputId": "e2872caf-480b-49b8-959c-6a103da66f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "# leer imagen\n",
        "img = cv2.imread('tarea_01//images//old.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# mostrar imagen\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
        "plt.axis('off')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V6hz0eHOsMv"
      },
      "source": [
        "Como se puede observar, esta imagen posee un muy bajo contraste. Claramente los valores en la imagen no utilizan todo el rango de intensidades `[0, 255]`. Para corregir esto, se puede aplicar una transformación lineal punto a punto.\n",
        "\n",
        "(a) Analice el histograma de la imagen y determine el rango de intensidades contenido esta (obtenga los valores `min` y `max` correspondientes). Luego, considerando estos límites (`v_min` y `v_max`), aplique la transformación `stretching`:\n",
        "\n",
        "`new_px = 255*(px - v_min)/(v_max - v_min)`\n",
        "\n",
        "sobre cada uno de los pixeles en la imagen y visualice el resultado.\n",
        "\n",
        "TIP: Al operar numéricamente los valores de una imagen `np.uint8`, suele convenir transformar esta a valores punto flotante `np.float32`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQm2QXB5QstR",
        "outputId": "91ea87c6-4d32-4f20-da77-996a0eb109f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# RESPUESTA PREGUNTA 1 PARTE 2.a\n",
        "\n",
        "# leer imagen\n",
        "img = cv2.imread('tarea_01//images//old.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# transformar imagen a np.float32\n",
        "img = img.astype(np.float32)\n",
        "\n",
        "# plotear histograma de la imagen\n",
        "flat = img.flatten()\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.hist(flat)\n",
        "\n",
        "# defina valores v_min y v_max (puede utilizar np.min y np.max si lo prefiere\n",
        "v_min = np.min(img)\n",
        "v_max = np.max(img)\n",
        "\n",
        "# transformar imagen\n",
        "for i in range(img.shape[0]):\n",
        "  for j in range(img.shape[1]):\n",
        "    # aplicar transformación\n",
        "    img[i, j] = 255*(img[i, j] - v_min)/(v_max - v_min)\n",
        "\n",
        "# transformar imagen a np.uint8\n",
        "img = img.astype(np.uint8)\n",
        "\n",
        "# mostrar imagen\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
        "plt.axis('off')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdPgfNreUOpa"
      },
      "source": [
        "(b) Siguiendo el mismo procedimiento, normalice los valores de intensidad de la imagen entre `[0, 1]` y luego aplique la transformación:\n",
        "\n",
        "`new_px = log( px + alpha )`\n",
        "\n",
        "sobre la imagen. Puede que sea necesario aplicar un último streching al rango `[0, 255]` posterior a la transformación.\n",
        "\n",
        "¿Cuales son los efectos de esta operación? ¿Por qué se necesita el parámetro \u000b `alpha` y como afecta este los resultados? ¿Cual es\n",
        "un valor adecuado para `alpha`? Muestre los resultados.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epr_FL7VUNeS",
        "outputId": "21e801ab-7ccd-4cee-bf4a-c2b84cef1bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# RESPUESTA PREGUNTA 1 PARTE 2.b\n",
        "\n",
        "# leer imagen\n",
        "img = cv2.imread('tarea_01//images//old.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# transformar imagen a np.float32\n",
        "img = img.astype(np.float32)\n",
        "\n",
        "# plotear histograma de la imagen\n",
        "\n",
        "flat = img.flatten()\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.hist(flat)\n",
        "\n",
        "# normalizar imagen (stretch entre 0 y 1)\n",
        "\n",
        "v_min = np.min(img)\n",
        "v_max = np.max(img)\n",
        "\n",
        "for i in range(img.shape[0]):\n",
        "  for j in range(img.shape[1]):\n",
        "    img[i, j] = (img[i, j] - v_min)/(v_max - v_min)\n",
        "\n",
        "# transformar imagen\n",
        "alpha = 0.2\n",
        "\n",
        "for i in range(img.shape[0]):\n",
        "  for j in range(img.shape[1]):\n",
        "    img[i, j] = np.log( img[i, j] + alpha)\n",
        "    \n",
        "# plotear histograma de la imagen transformada\n",
        "\n",
        "flat = img.flatten()\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.hist(img.flatten(), 40)\n",
        "\n",
        "\n",
        "# normalizar imagen (stretch entre 0 y 255)\n",
        "\n",
        "v_min = np.min(img)\n",
        "v_max = np.max(img)\n",
        "\n",
        "for i in range(img.shape[0]):\n",
        "  for j in range(img.shape[1]):\n",
        "    img[i, j] = 255*(img[i, j] - v_min)/(v_max - v_min)\n",
        "\n",
        "# transformar imagen a np.uint8\n",
        "\n",
        "img = img.astype(np.uint8)\n",
        "\n",
        "# mostrar imagen\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# La imagen se ve más pixeleada que la anterior, el parámetro alpha permite\n",
        "# ajustar manualmente el contraste de la imagen, si alpha aumenta, la imagen \n",
        "# se oscurece, si disminuye, la imagen se aclara. A mi parecer la imagen se ve\n",
        "# óptima con un alpha en torno a 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtq1iTVirC9b"
      },
      "source": [
        "## Parte 3\n",
        "\n",
        "Considere la imagen de monedas `coins.png`. Se desea elaborar un algoritmo que permita clasificar cada una de las monedas de acuerdo a su tamaño. En la parte 1 de este problema se vio como es posible segmentar los cuerpos de una imagen mediante la binarización adecuada de esta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR9cONaDr52c",
        "outputId": "cd89777e-61da-4e50-ffb8-081d95101baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "# leer imagen\n",
        "img = cv2.imread('tarea_01//images//coins.png')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# convertir a escala de grises\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_gray, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# binarizar con cv2.inRange (los valores de la máscara deben estar entre 0 y 1)\n",
        "mask = cv2.inRange(img_gray, 90, 255)\n",
        "mask = mask/255\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(mask, cmap='gray')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMPBG5FVstNv"
      },
      "source": [
        "No obstante, esto no permite aislar cada una de las monedas por si sola ya que estas son relativamente del mismo color (o máás bien, tonalidad de gris). Para resolver esto, se puede utilizar el algoritmo `Connected Componentes` (implementado en `cv2.connectedComponents`) el cual, a partir de una imagen binarizada etiqueta cada uno de los cuerpos presentes. Esto último permite acceder a cada uno de los cuerpos mediante su etiqueta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8L4RxcxtL8A",
        "outputId": "06f561a7-dd51-40b3-ccd5-0a3cc979cc2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# leer imagen\n",
        "img = cv2.imread('tarea_01//images//coins.png')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# convertir a escala de grises\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# binarizar con cv2.inRange (los valores de la máscara deben estar entre 0 y 1)\n",
        "mask = cv2.inRange(img_gray, 90, 255)/255\n",
        "mask = np.uint8(mask)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(mask, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# etiquetar mediante connected components\n",
        "# retorna cantidad de cuerpos identificados y una imagen con las etiquetas\n",
        "num_coins, labels = cv2.connectedComponents(mask)\n",
        "\n",
        "print('monedas identificadas: {:d}'.format((num_coins - 1)))\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(labels, cmap='jet')\n",
        "plt.axis('off')\n",
        "\n",
        "# acceder a moneda con etiqueta 6\n",
        "coin_6 = np.uint8( labels==6 )\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(coin_6, cmap='gray')\n",
        "plt.axis('off')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWoft8WYvW7v"
      },
      "source": [
        "(a) Utilizando un `for loop` itere sobre las monedas y clasifiquelas a partir de su tamaño (note que puede hacer esto a partir de su área o cantidad de piexeles), genere una imagen con las monedas grandes y otra con las monedas pequeñas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAP8uX9OwR24",
        "outputId": "920b8738-b0df-4cb4-c732-788990bbd585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# RESPUESTA PREGUNTA 1 PARTE 3\n",
        "\n",
        "# leer imagen\n",
        "img = cv2.imread('tarea_01//images//coins.png')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# convertir a escala de grises\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# binarizar con cv2.inRange (los valores de la máscara deben estar entre 0 y 1)\n",
        "mask = cv2.inRange(img_gray, 90, 255)/255\n",
        "mask = np.uint8(mask)\n",
        "\n",
        "# etiquetar mediante connected components\n",
        "num_coins, labels = cv2.connectedComponents(mask)\n",
        "\n",
        "# inicializar imágenes de monedas pequeñas y grandes\n",
        "small_coins = np.zeros_like(mask)\n",
        "big_coins = np.zeros_like(mask)\n",
        "\n",
        "# para cada una de las etiquetas identificadas\n",
        "for i in np.arange(1,num_coins):\n",
        "  coin_i = np.uint8( labels==i )\n",
        "  area_i = np.sum( coin_i[:, :] )\n",
        "  # si el área de la moneda coin_i corresponde a moneda pequeña\n",
        "  # la cota se eligió viendo todos los area_i\n",
        "  if area_i < 1300:\n",
        "    # agregar mask a small_coins (sume las imágenes)\n",
        "    small_coins += coin_i\n",
        "  # else\n",
        "  else:\n",
        "    # agregar mask a big_coins (sume las imágenes)\n",
        "    big_coins += coin_i\n",
        "\n",
        "# visualizar resultados\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(small_coins, cmap='gray')\n",
        "plt.title(\"Monedas pequeñas\")\n",
        "plt.axis('off')\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(big_coins, cmap='gray')\n",
        "plt.title(\"Monedas grandes\")\n",
        "plt.axis('off')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irz1udqRYtoT"
      },
      "source": [
        "# Problema 2\n",
        "La empresa de manufactura NERV S.A, dedicada al mecanizado y corte de piezas metálicas, ha decidido automatizar su sistema de control de calidad con el fin de acelerar la producción y reducir el número de piezas defectuosas en la línea de ensamblaje. Por esta razón, se le ha encargado a usted desarrollar un sistema de visión computacional que permita identificar aquellas piezas cuyas medidas escapen de las tolerancias especificadas.\n",
        "\n",
        "La pieza que actualmente se encuentra en producción corresponde a la pieza en aluminio mostrada en la imagen `part_ref.png`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvSAybXZYtoW",
        "outputId": "c0d6eee1-396c-40f4-e872-6d2081a9214d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# leer imagen\n",
        "img = cv2.imread('tarea_01//images//part_ref.png')\n",
        "\n",
        "# transformar a RGB\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# mostrar imagen\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhmuI8TxYtod"
      },
      "source": [
        "Durante la inspección de calidad solo se ha de revisar:\n",
        "- **El ángulo del corte oblicuo de la izquierda.**\n",
        "- **La posición de las dos perforaciones de la izquiera respecto a la perforación de la derecha.**\n",
        "\n",
        "Las especificaciones de estas medidas se presentan en la imagen `part_spec.png`. Notar que las tolerancias se presentan en **porcentajes**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUW-MXFYYtof"
      },
      "source": [
        "## Parte 1\n",
        "Dado que en la línea de ensamblaje vienen muchas piezas juntas, es necesario segmentar y etiquetar cada una de éstas para luego aislarlas y procesarlas individualmente. Esto se conoce como `masking`, pues es generar una máscara para cada una de las piezas.\n",
        "\n",
        "Considerando la imagen `batch_1.png`, escriba el código necesario para cumplir lo anterior. En particular, se espera que el resultado de este proceso sea una matriz `labels` (`np.array`), de las mismas dimensiones de la imagen, que contenga las etiquetas de cada uno de los pixeles en la imagen. Así, al escribir:\n",
        "\n",
        "`part_1 = np.uint8( (labels==1)*255 )`\n",
        "\n",
        "`plt.imshow(part_1, cmap='gray')`\n",
        "\n",
        "Se obtiene la imagen `result_part_1.png`.\n",
        "\n",
        "TIP: utilice `cv2.connectedComponents` y note que el fondo de la imagen es de color azul."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGgq7w2LYtoh",
        "outputId": "9fb47003-a6f2-42a3-fe56-e1737e608a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "## RESPUESTA PREGUNTA 2 PARTE 1\n",
        "\n",
        "# leer imagen\n",
        "img = cv2.imread('tarea_01//images//batch_1.png')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# segmentar/binarizar respecto al background\n",
        "\n",
        "# Se extrae el fondo azul\n",
        "img_sin_azul = np.zeros_like(img)\n",
        "img_sin_azul[:,:,0] = img[:,:,0]\n",
        "\n",
        "gray= cv2.cvtColor(img_sin_azul, cv2.COLOR_RGB2GRAY)\n",
        "mask = cv2.inRange(gray, 35, 255)/255\n",
        "mask = np.uint8(mask)\n",
        "\n",
        "# etiquetar mediante connected components\n",
        "num_components, labels = cv2.connectedComponents(mask)\n",
        "\n",
        "# visualizar pieza número 1\n",
        "part_1 = np.uint8( (labels==1)*255 )\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(part_1, cmap='gray')\n",
        "plt.axis('off')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx1tQXiJYtom"
      },
      "source": [
        "## Parte 2\n",
        "Habiendo identificado cada una de las piezas mediante una etiqueta, ahora es posible procesarlas por separado.\n",
        "\n",
        "En primer lugar, procese la imagen tal de obtener los bordes de la pieza como en la imagen a continuación. Pruebe con los algoritmos de detección de bordes `cv2.Sobel` y `cv2.Canny`, y comente cúal de estos funciona mejor.\n",
        "\n",
        "TIP: puede consultar el funcionamiento de estas funciones en la documentación de OpenCV.\n",
        "\n",
        "TIP2: puede serle útil la función `cv2.bitwise_or` para combinar imágenes binarias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6wCOGYjYtoo",
        "outputId": "ab0a6c7b-dc19-4504-9e8c-09757ec560cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        }
      },
      "source": [
        "## RESPUESTA PREGUNTA 2 PARTE 2\n",
        "\n",
        "# sobel (cv2.Sobel)\n",
        "edge_sobel = cv2.Sobel(part_1, cv2.CV_16S, 0, 1, ksize=5)\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(edge_sobel, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# canny (cv2.Canny)\n",
        "edge_canny = cv2.Canny(part_1, 0, 1)\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(edge_canny, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# Con Sobel no se pueden apreciar todos los bordes, y si se aumenta el kernel se\n",
        "# genera bastante ruido, por otro lado, Canny entrega el resultado deseado, los\n",
        "# bordes se aprecian con claridad."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sftty41bYtov"
      },
      "source": [
        "## Parte 3.1\n",
        "Con los bordes de la pieza aislados, se pueden aplicar las transformadas de Hough para reconocimiento geométrico. Complete la implementación de la transformada de Hough de rectas (`myHough(part_edges)`) para obtener el ángulo de corte de la pieza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0G_cmg5Ytox",
        "outputId": "1f734a59-2133-4426-9213-11d1e12a2e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## RESPUESTA PREGUNTA 2 PARTE 3.1\n",
        "\n",
        "def myHough(part_edges):\n",
        "    \"\"\"\n",
        "    -> float\n",
        "    \n",
        "    Obtiene el ángulo de corte de la pieza a partir de los bordes de esta.\n",
        "    \n",
        "    :param np.array part_edges:\n",
        "        imagen binaria que contiene los bordes de la pieza a analizar.\n",
        "    \n",
        "    :returns:\n",
        "        ángulo de corte izquierdo.\n",
        "    \"\"\"\n",
        "    # inicializar matriz H del espacio de Hough\n",
        "    m = np.linspace(-8, 8, 300)\n",
        "    n = np.linspace(-100, 600, 900)\n",
        "    H = np.zeros( (m.size, n.size) )\n",
        "    \n",
        "    # por cada pixel (i, j) en la imagen part_edges\n",
        "    for i in range( part_edges.shape[0] ):\n",
        "      for j in range( part_edges.shape[1] ):\n",
        "      \n",
        "      # si part_edges(i, j) = 1 (borde)\n",
        "        if part_edges[i, j] == 1:\n",
        "          \n",
        "          # para cada pendiente m_i dentro del espacio de Hough\n",
        "          for m_i in m:\n",
        "              \n",
        "              # calcular valor n_i correspondiente\n",
        "              n_i = j - m_i*i\n",
        "             \n",
        "              # si n_i se encuentra dentro del espacio de Hough\n",
        "              if (n_i > -100) and (n_i < 600):\n",
        "               \n",
        "                # obtener indices m_idx y n_idx correspondientes para asignar voto\n",
        "                n_idx = np.argmin( abs(n - n_i) )\n",
        "                m_idx = np.argmin( abs(m - m_i) )\n",
        "                \n",
        "                # agregar voto a H[m_idx, n_idx]\n",
        "                H[m_idx, n_idx] = H[m_idx, n_idx] + 1            \n",
        "    \n",
        "    # segmentar puntos en H con mayor cantidad de votos\n",
        "    pendientes = []\n",
        "    for i in range(m.size):\n",
        "      for j in range(n.size):\n",
        "        if H[i, j] > 40: # Este número se determinó por tanteo\n",
        "          pendiente = -8+i*16/300\n",
        "          pendientes.append(pendiente)           \n",
        "\n",
        "    # calcular ángulos a partir de cada uno de estos puntos (usar pendientes)\n",
        "    angulos = np.arctan(pendientes)*180/np.pi\n",
        "    \n",
        "    # retornar promedio de los ángulos obtenidos\n",
        "    promedio = np.sum(angulos)/len(angulos)\n",
        "    return promedio\n",
        "\n",
        "# probar función\n",
        "cut_angle = myHough(edge_canny/255)\n",
        "\n",
        "print('ángulo de corte identificado: {:f} grados.'.format(cut_angle))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnUswVM6Yto3"
      },
      "source": [
        "## Parte 3.2\n",
        "\n",
        "OpenCV también contiene implementaciones de las transformadas de Hough: `cv2.HoughLines` y `cv2.HoughCircles`. Utilizando estos algoritmos, obtenga el ángulo del corte izquierdo y las posiciones de las tres perforaciones. Puede usar `result_part_3.png` como referencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5bw1w3ZYto5",
        "outputId": "0f0efae2-09a5-4852-a420-6415e51c51a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "## RESPUESTA PREGUNTA 2 PARTE 3.2\n",
        "\n",
        "# aplicar transformada de Hough (cv2.HoughLines)\n",
        "lines = cv2.HoughLines(edge_canny, 1, np.pi/360, 100)\n",
        "                       \n",
        "# obtener ángulo de corte\n",
        "cut_angle = []\n",
        "\n",
        "# para cada una de las líneas detectadas\n",
        "for line in lines:\n",
        "  rho, theta = line[0]\n",
        "  \n",
        "  # si el ángulo es cercano a 30°\n",
        "  if abs(theta*180/np.pi - 30.0) < 20.0:\n",
        "    \n",
        "    # agregar ángulo a la lista (en grados)\n",
        "    cut_angle.append( theta*(180/np.pi) )\n",
        "\n",
        "# promediar resultado y obtener estimación de ángulo\n",
        "cut_angle = sum(cut_angle)/len(cut_angle)\n",
        "print(cut_angle)\n",
        "\n",
        "# transformada hough circulos (cv2.HoughCircles)\n",
        "circles = cv2.HoughCircles(edge_canny, cv2.HOUGH_GRADIENT, 1, 20, param1 = 50, param2 = 30, minRadius = 0, maxRadius = 1000)\n",
        "\n",
        "# separar perforaciones\n",
        "perf_izq = []\n",
        "perf_der = []\n",
        "for c in circles[0]:\n",
        "    \n",
        "    # si es de las perforaciones menores (radio < 15px)\n",
        "    if c[2] < 15:\n",
        "        perf_izq.append( list(c) )\n",
        "    \n",
        "    # si es la perforación mayor   \n",
        "    else:\n",
        "        perf_der = c   \n",
        "print(perf_izq)\n",
        "print(perf_der)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2U7nIVXYto-"
      },
      "source": [
        "## Parte 4\n",
        "Ahora que ha logrado obtener las medidas de una pieza, repita el proceso anterior con la imagen `part_ref.png` para obtener las medidas de referencia. Luego, implemente la función `detect_faulty_parts(img)` que, tomando como input una imagen como `batch_1.png`, detecte las piezas defectuosas en la imagen y ponga una máscara roja sobre éstas como en la imagen a continuación (`result_part_4.png`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNTORR_pYtpA",
        "outputId": "306eff5c-c5ad-4299-dc1c-b7958523f2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "source": [
        "## RESPUESTA PREGUNTA 2 PARTE 4\n",
        "\n",
        "# Medidas de referencia:\n",
        "# Se aplica el mismo proceso que en las partes anteriores\n",
        "ref = cv2.imread('tarea_01//images//part_ref.png')\n",
        "ref = cv2.cvtColor(ref, cv2.COLOR_BGR2RGB)\n",
        "ref_sin_azul = np.zeros_like(ref)\n",
        "ref_sin_azul[:,:,0] = ref[:,:,0]\n",
        "gray= cv2.cvtColor(ref_sin_azul, cv2.COLOR_RGB2GRAY)\n",
        "mask = cv2.inRange(gray, 35, 255)/255\n",
        "mask = np.uint8(mask)\n",
        "canny = cv2.Canny(mask, 0, 1)\n",
        "circ = cv2.HoughCircles(canny, cv2.HOUGH_GRADIENT, 1, 20, param1 = 50, \n",
        "                        param2 = 30, minRadius = 0, maxRadius = 1000)\n",
        "c_izq = []\n",
        "c_der = []\n",
        "for c in circ[0]:\n",
        "    if c[2] < 15:\n",
        "        c_izq.append( list(c) )   \n",
        "    else:\n",
        "        c_der = c   \n",
        "print(\"Referencia para perforaciones izquierda: \", c_izq)\n",
        "print(\"Referencia para perforaciones derecha: \", c_der)\n",
        "k1 = c_der[0] - c_izq[0][0]  # Distancia horizontal ptos izquierda y derecha\n",
        "k2 = c_izq[0][1] - c_der[1]  # Distancia vertical ptos izquierda y derecha\n",
        "\n",
        "\n",
        "def detect_faulty_parts(img):\n",
        "    \"\"\"\n",
        "    -> Image (np.array)\n",
        "    Detecta en la imagen aquellas piezas que no cumplan con las especificaciones de diseño.\n",
        "    \n",
        "    :param np.array img:\n",
        "        imagen en RGB que contiene las piezas a analizar.\n",
        "    \n",
        "    :returns:\n",
        "        imagen con las piezas defectuosas identificadas con rojo.\n",
        "    \"\"\"\n",
        "    # segmentar/binarizar respecto al background (parte 1)\n",
        "    segmentacion = np.zeros_like(img)\n",
        "    segmentacion[:,:,0] = img[:,:,0]\n",
        "    gray = cv2.cvtColor(segmentacion, cv2.COLOR_RGB2GRAY)\n",
        "    mask = cv2.inRange(gray, 35, 255)/255\n",
        "    mask = np.uint8(mask)\n",
        "\n",
        "   \n",
        "    # inicializar imagen que contendrá las máscaras de las piezas malas\n",
        "    faulty_parts = np.zeros_like(mask)\n",
        "    \n",
        "    # etiquetar mediante connected components (parte 1)\n",
        "    num_parts, labels = cv2.connectedComponents(mask)\n",
        "    \n",
        "    # procesar cada una de las piezas en la imagen\n",
        "    for i in range(1, num_parts):\n",
        "      \n",
        "      # separar pieza\n",
        "      part_img = (labels == i)*255\n",
        "      part_img = np.uint8(part_img)\n",
        "      \n",
        "      # obtener bordes/edges (parte 2)\n",
        "      edges = cv2.Canny(part_img, 0, 1)\n",
        "      \n",
        "      # aplicar transformada de Hough de rectas y obtener ángulo de corte (parte 3)\n",
        "      lines = cv2.HoughLines(edges, 1, np.pi/360, 100)\n",
        "      cut_angle = []\n",
        "      for line in lines:\n",
        "        rho, theta = line[0]\n",
        "        if abs(theta*180/np.pi - 30.0) < 20:\n",
        "          cut_angle.append( theta*(180/np.pi) )\n",
        "      cut_angle = 90 - sum(cut_angle)/len(cut_angle)\n",
        "      \n",
        "      # aplicar transformada de Hough de circulos y obtener dimensiones perfs. (parte 3)\n",
        "      circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20, param1 = 50,\n",
        "                                 param2 = 30, minRadius = 0, maxRadius = 1000)\n",
        "      perf_izq = []\n",
        "      perf_der = []\n",
        "      for c in circles[0]:\n",
        "        if c[2] < 15:\n",
        "          perf_izq.append( list(c) ) \n",
        "        else:\n",
        "          perf_der = c\n",
        "      \n",
        "      # checkear cumplimiento especificaciones\n",
        "      VALID_PART = True\n",
        "        \n",
        "      try:\n",
        "        \n",
        "        # si ángulo de corte está fuera de la tolerancia\n",
        "        assert abs( cut_angle - 60 ) < 60*0.05\n",
        "\n",
        "        # tolerancias de distancias\n",
        "        assert abs( abs(perf_izq[0][0]-perf_der[0]) -k1 ) < k1*0.05\n",
        "        assert abs( abs(perf_izq[1][0]-perf_der[0]) -k1 ) < k1*0.05\n",
        "        \n",
        "        assert abs( abs(perf_izq[0][1]-perf_der[1]) -k2 ) < k2*0.1\n",
        "        assert abs( abs(perf_izq[1][1]-perf_der[1]) -k2 ) < k2*0.1\n",
        "\n",
        "      except AssertionError:\n",
        "        # pieza está mala\n",
        "        VALID_PART = False\n",
        "      \n",
        "      # si la pieza está defectuosa\n",
        "      if not(VALID_PART):\n",
        "        faulty_parts = faulty_parts + part_img\n",
        "\n",
        "    # aplicar máscara roja (faulty_parts) sobre la imagen original\n",
        "    # Se extrae todo menos las piezas defetuosas de img\n",
        "    fallas=cv2.bitwise_or(img, img, mask=faulty_parts) \n",
        "    # Se eliminan las fallas de img\n",
        "    res=img-fallas\n",
        "    # Se reemplazan las fallas por la máscara en el canal r\n",
        "    res[:,:,0]=faulty_parts+res[:,:,0]\n",
        "    return res\n",
        "\n",
        "# probar la función\n",
        "test_batch = cv2.imread('tarea_01//images//batch_1.png')\n",
        "test_batch = cv2.cvtColor(test_batch, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "ret = detect_faulty_parts(test_batch)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(ret)\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTOpzq3aYtpF"
      },
      "source": [
        "## Parte 5\n",
        "Dado el buen funcionamiento de su sistema, la gerencia ha decidido combinar la línea de ensamblaje actual con la del nuevo modelo. Estas últimas presentan el nuevo logo de la empresa y siguen especificaciones distintas a la del antiguo modelo.\n",
        "\n",
        "Utilizando SIFT (`cv2.xfeatures2d.SIFT_create`), modifique la función `detect_faulty_parts(img)` tal que se detecte el modelo de cada pieza y se analicen únicamente las del modelo antiguo. Puede copiar la función anterior y agregar un bloque en el que se identifique el logo de la pieza, si la pieza es del modelo nuevo puede utilizar `continue` para saltar a la siguiente pieza en el `for`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPrw_rEYYtpH",
        "outputId": "884826a5-2076-4dc6-8a8a-832cb0df3175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "## RESPUESTA PREGUNTA 2 PARTE 5\n",
        "\n",
        "def detect_faulty_parts_2(img):\n",
        "    \"\"\"\n",
        "    -> Image (np.array)\n",
        "    Detecta en la imagen aquellas piezas que no cumplan con las especificaciones de diseño.\n",
        "    \n",
        "    :param np.array img:\n",
        "        imagen en RGB que contiene las piezas a analizar.\n",
        "    \n",
        "    :returns:\n",
        "        imagen con las piezas defectuosas identificadas con rojo.\n",
        "    \"\"\"\n",
        "\n",
        "    # segmentar/binarizar respecto al background (parte 1)\n",
        "    img_gray=cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    segmentacion = np.zeros_like(img)\n",
        "    segmentacion[:,:,0] = img[:,:,0]\n",
        "    gray = cv2.cvtColor(segmentacion, cv2.COLOR_RGB2GRAY)\n",
        "    mask = cv2.inRange(gray, 35, 255)/255\n",
        "    mask = np.uint8(mask) \n",
        "\n",
        "    # inicializar imágen que contendrá las máscaras de las piezas malas\n",
        "    faulty_parts = np.zeros_like(mask)\n",
        "\n",
        "    # etiquetar mediante connected components (parte 1)\n",
        "    num_parts, labels = cv2.connectedComponents(mask)\n",
        "\n",
        "    # segmentar logos rojos desde la imagen original\n",
        "    logos = cv2.inRange(gray, 70, 255) #Cota obtenida por tanteo\n",
        "\n",
        "    # procesar cada una de las piezas en la imagen\n",
        "    for i in range(1, num_parts):\n",
        "\n",
        "      # aislar pieza y logo correspondiente\n",
        "      part_img = (labels == i)\n",
        "      part_img = np.uint8(part_img)*255\n",
        "      part_logo = np.multiply(logos, part_img)\n",
        "      \n",
        "      # checkear si el logo es del modelo antiguo\n",
        "      sift = cv2.xfeatures2d.SIFT_create()\n",
        "\n",
        "      # obtener descriptores referencia mediante sift.detectAndCompute\n",
        "      ref = cv2.imread('tarea_01//images//old_model_logo.png')\n",
        "      ref = cv2.cvtColor(ref, cv2.COLOR_RGB2GRAY)\n",
        "      kp_ref, des_ref = sift.detectAndCompute(ref, mask=None)\n",
        "\n",
        "      # obtener descriptores del logo mediante sift.detectAndCompute\n",
        "      kp_logo, des_logo = sift.detectAndCompute(img_gray, mask=part_logo) \n",
        "\n",
        "      # realizar brute force matching entre los descriptores\n",
        "      BruteForce = cv2.BFMatcher()\n",
        "      matches = BruteForce.knnMatch(des_ref, des_logo, k=2)\n",
        "      \n",
        "      # filtrar buenos matches\n",
        "      good_matches = []\n",
        "      for m1, m2 in matches:\n",
        "        r=0.75  #  Con este r se escogen los mejores matches\n",
        "        if m1.distance < r*m2.distance:\n",
        "          good_matches.append(m1)\n",
        "\n",
        "      # si no hay matches (no es logo antiguo)\n",
        "      if len(good_matches) < 1:\n",
        "          continue\n",
        "\n",
        "      # obtener bordes/edges (parte 2)\n",
        "      edges = cv2.Canny(part_img, 0, 1)\n",
        "\n",
        "      # aplicar transformada de Hough de rectas y obtner ángulo de corte (parte 3)\n",
        "      lines = cv2.HoughLines(edges, 1, np.pi/360, 100)\n",
        "      cut_angle = []\n",
        "      for line in lines:\n",
        "        rho, theta = line[0]\n",
        "        if abs(theta*180/np.pi - 30.0) < 20:\n",
        "          cut_angle.append( theta*(180/np.pi) )\n",
        "      cut_angle = 90 - sum(cut_angle)/len(cut_angle)\n",
        "\n",
        "      # aplicar transformada de Hough de circulos y obtener dimensiones perfs. (parte 3)\n",
        "      circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20, param1 = 50,\n",
        "                                 param2 = 30, minRadius = 0, maxRadius = 1000)\n",
        "      perf_izq = []\n",
        "      perf_der = []\n",
        "      for c in circles[0]:\n",
        "        if c[2] < 15:\n",
        "          perf_izq.append( list(c) ) \n",
        "        else:\n",
        "          perf_der = c\n",
        "\n",
        "      # checkear cumplimiento especificaciones\n",
        "      VALID_PART = True\n",
        "        \n",
        "      try:\n",
        "        \n",
        "        # si ángulo de corte está fuera de la tolerancia\n",
        "        assert abs( cut_angle - 60 ) < 60*0.05\n",
        "\n",
        "        # tolerancias de distancias\n",
        "        assert abs( abs(perf_izq[0][0]-perf_der[0]) -k1 ) < k1*0.05\n",
        "        assert abs( abs(perf_izq[1][0]-perf_der[0]) -k1 ) < k1*0.05\n",
        "        \n",
        "        assert abs( abs(perf_izq[0][1]-perf_der[1]) -k2 ) < k2*0.1\n",
        "        assert abs( abs(perf_izq[1][1]-perf_der[1]) -k2 ) < k2*0.1\n",
        "\n",
        "      except AssertionError:\n",
        "        # pieza está mala\n",
        "        VALID_PART = False\n",
        "      \n",
        "      # si la pieza está defectuosa\n",
        "      if not(VALID_PART):\n",
        "        faulty_parts = faulty_parts + part_img\n",
        "\n",
        "    # aplicar máscara roja (faulty_parts) sobre la imagen original\n",
        "    #Se extrae todo menos las piezas defetuosas de img\n",
        "    fallas=cv2.bitwise_or(img, img, mask=faulty_parts) \n",
        "    #Se eliminan las fallas de img\n",
        "    res=img-fallas\n",
        "    #Se reemplazan las fallas por la máscara en el canal r\n",
        "    res[:,:,0]=faulty_parts+res[:,:,0]\n",
        "    return res\n",
        "\n",
        "# probar la función\n",
        "test_batch = cv2.imread('tarea_01//images//batch_2.png')\n",
        "test_batch = cv2.cvtColor(test_batch, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "ret = detect_faulty_parts_2(test_batch)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(ret)\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}